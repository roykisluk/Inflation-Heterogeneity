{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inflation_analysis import grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2021\n",
    "end_year = 2022\n",
    "years = range(start_year, end_year+1)\n",
    "base_year = start_year\n",
    "group_mmb = None \n",
    "factor = 1\n",
    "cex_data_folder = '/Users/roykisluk/Downloads/Consumer_Expenditure_Survey/' \n",
    "folder_names_pathname = 'Data_clean/CEX_folder_names.csv' \n",
    "prodcode_dict_pathname = 'Data_clean/prodcode_dictionary_c3-c399.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality, observance, income, ses, age, family_size, total_misparmb = grouping(start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_year is None:   \n",
    "    base_year = start_year\n",
    "years = range(start_year, end_year + 1)\n",
    "\n",
    "groups_mmb = {key: {} for key in groups.keys()}\n",
    "for key in groups:\n",
    "    for year in years:\n",
    "        groups_mmb[key][year] = groups[key][year][['misparmb']]\n",
    "\n",
    "group_analysis = {}\n",
    "for key in groups.keys():\n",
    "    group_number = list(groups.keys()).index(key) + 1\n",
    "    total_groups = len(groups)\n",
    "    print(groups_mmb[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mmb = groups_mmb['Arab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "years = range(start_year, end_year + 1)\n",
    "\n",
    "# Load folder names\n",
    "folder_names_df = pd.read_csv(folder_names_pathname)\n",
    "\n",
    "# Functions\n",
    "\n",
    "# Aggregate total consumption for this group\n",
    "def total_consumption_value(df): \n",
    "    total_consumption = 0.0\n",
    "    for j in range(0, len(df)):\n",
    "        total_consumption += df['mehir'][j]\n",
    "    return total_consumption\n",
    "\n",
    "# Keep only shared prodcodes for both dataframes (years)\n",
    "def keep_shared_prodcodes(df1, df2):\n",
    "    shared_prodcodes = set(df1['prodcode']).intersection(set(df2['prodcode']))\n",
    "    df1_shared = df1[df1['prodcode'].isin(shared_prodcodes)].reset_index(drop=True)\n",
    "    df2_shared = df2[df2['prodcode'].isin(shared_prodcodes)].reset_index(drop=True)\n",
    "    return df1_shared, df2_shared\n",
    "\n",
    "def weighting(df):\n",
    "    weights = pd.DataFrame(df['prodcode'].unique(), columns=['prodcode'])\n",
    "    weights['weight'] = 0.0\n",
    "    total_consumption = total_consumption_value(df)\n",
    "    for j in range(0, len(weights)):\n",
    "        weights.loc[j, 'weight'] = df[df['prodcode'] == weights.loc[j, 'prodcode']]['mehir'].sum() / total_consumption\n",
    "    return weights\n",
    "\n",
    "def average_price(df):\n",
    "    average_prices = pd.DataFrame(df['prodcode'].unique(), columns=['prodcode'])\n",
    "    average_prices['price'] = 0.0\n",
    "    for j in range(0, len(average_prices)):\n",
    "        average_prices.loc[j, 'price'] = (df[df['prodcode'] == average_prices.loc[j, 'prodcode']]['mehir'] / df[df['prodcode'] == average_prices.loc[j, 'prodcode']]['kamut']).mean()\n",
    "    return average_prices\n",
    "\n",
    "def Laspeyres(df_base, df_current):\n",
    "    index_df = pd.DataFrame(df_base['prodcode'].unique(), columns=['prodcode'])\n",
    "    index_df['index'] = 0.0\n",
    "    weights = weighting(df_base)\n",
    "    average_prices_base = average_price(df_base)\n",
    "    average_prices_current = average_price(df_current)\n",
    "    index_df = index_df.merge(weights, on='prodcode', how='left')\n",
    "    index_df = index_df.merge(average_prices_base, on='prodcode', how='left', suffixes=('', '_base'))\n",
    "    index_df = index_df.merge(average_prices_current, on='prodcode', how='left', suffixes=('_base', '_current'))\n",
    "    total_index = 0.0\n",
    "    missing_base_prices = 0\n",
    "    missing_current_prices = 0\n",
    "    for j in range(len(index_df)):\n",
    "        price_current = index_df.loc[j, 'price_current']\n",
    "        price_base = index_df.loc[j, 'price_base']\n",
    "        if price_base == 0 or pd.isna(price_base) or np.isinf(price_base):\n",
    "            index_df.loc[j, 'index'] = factor * 100\n",
    "            missing_base_prices += 1\n",
    "            continue\n",
    "        if price_current == 0 or pd.isna(price_current) or np.isinf(price_current):\n",
    "            index_df.loc[j, 'index'] = factor * 100\n",
    "            missing_current_prices += 1\n",
    "            continue\n",
    "        index_df.loc[j, 'index'] = (price_current / price_base) * 100\n",
    "    for j in range(len(index_df)):\n",
    "        weight = index_df.loc[j, 'weight']\n",
    "        total_index += weight * index_df.loc[j, 'index']\n",
    "    return index_df, total_index\n",
    "\n",
    "def merge_to_secondary(df):\n",
    "    df['prodcode_secondary'] = df['prodcode'].astype(str).str[:3]\n",
    "    grouped = df.groupby('prodcode_secondary', group_keys=False).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'price_index': np.average(x['index'], weights=x['weight']) if x['weight'].sum() > 0 else np.nan,\n",
    "            'total_weight': x['weight'].sum()\n",
    "        }),\n",
    "        include_groups=False \n",
    "    ).reset_index()\n",
    "    grouped.rename(columns={'prodcode_secondary': 'prodcode'}, inplace=True)\n",
    "    grouped.rename(columns={'total_weight': 'weight'}, inplace=True)\n",
    "    return grouped\n",
    "\n",
    "def merge_to_primary(df):\n",
    "    df['prodcode_primary'] = df['prodcode'].astype(str).str[:2]\n",
    "    grouped = df.groupby('prodcode_primary', group_keys=False).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'price_index': np.average(x['price_index'], weights=x['weight']) if x['weight'].sum() > 0 else np.nan,\n",
    "            'total_weight': x['weight'].sum()\n",
    "        }),\n",
    "        include_groups=False\n",
    "    ).reset_index()\n",
    "    grouped.rename(columns={'prodcode_primary': 'prodcode'}, inplace=True)\n",
    "    grouped.rename(columns={'total_weight': 'weight'}, inplace=True)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load survey data for each year\n",
    "\n",
    "dfs_survey = {}\n",
    "for year in years:\n",
    "    subfolder = folder_names_df.loc[folder_names_df['Year'] == year, 'Folder_Name'].values[0]\n",
    "    data_prices_pathname = f\"{cex_data_folder}{subfolder}/{subfolder}datayoman.sas7bdat\"\n",
    "    df, meta = pyreadstat.read_sas7bdat(data_prices_pathname)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    dfs_survey[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs_survey[2021]['misparmb'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group_mmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter observations for relevant group\n",
    "if group_mmb is not None:\n",
    "    for year in years:\n",
    "        dfs_survey[year] = dfs_survey[year][dfs_survey[year]['misparmb'].isin(group_mmb[year]['misparmb'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs_survey[2021]['misparmb'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs_survey[2021]['misparmb'].nunique())\n",
    "print(dfs_survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs_survey[2021]['prodcode'].min())\n",
    "print(dfs_survey[2021]['prodcode'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter observations with prodcode that starts with 3\n",
    "for year in years:\n",
    "    dfs_survey[year] = dfs_survey[year][dfs_survey[year]['prodcode'].astype(str).str.startswith('3')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs_survey[2021]['prodcode'].min())\n",
    "print(dfs_survey[2021]['prodcode'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate weights and price indexes\n",
    "yearly_price_index = {}\n",
    "df_price_index = {}\n",
    "for year in years:\n",
    "    df_base, df_current = keep_shared_prodcodes(dfs_survey[base_year], dfs_survey[year])\n",
    "    df_price_index[year], yearly_price_index[year] = Laspeyres(df_base, df_current)\n",
    "\n",
    "# Combine all years into a single dataframe\n",
    "combined_df = pd.concat(df_price_index.values(), keys=df_price_index.keys(), names=['Year', 'Index']).reset_index(level='Index', drop=True).reset_index()\n",
    "combined_df = combined_df[['Year', 'prodcode', 'index', 'weight']]\n",
    "\n",
    "# Merge to secondary and primary categories\n",
    "df_secondary = {}\n",
    "df_primary = {}\n",
    "for year in years:\n",
    "    df_secondary[year] = merge_to_secondary(df_price_index[year])\n",
    "    df_primary[year] = merge_to_primary(df_secondary[year])\n",
    "\n",
    "# Combine secondary and primary categories into a single dataframe\n",
    "combined_secondary_df = pd.concat(df_secondary.values(), keys=df_secondary.keys(), names=['Year', 'Index']).reset_index(level='Index', drop=True).reset_index()\n",
    "combined_primary_df = pd.concat(df_primary.values(), keys=df_primary.keys(), names=['Year', 'Index']).reset_index(level='Index', drop=True).reset_index()\n",
    "\n",
    "# Keep only the necessary columns\n",
    "combined_secondary_df = combined_secondary_df[['Year', 'prodcode', 'price_index', 'weight']]\n",
    "combined_primary_df = combined_primary_df[['Year', 'prodcode', 'price_index', 'weight']]\n",
    "\n",
    "# Load prodcode dictionary\n",
    "prodcode_dict_df = pd.read_csv(prodcode_dict_pathname)\n",
    "\n",
    "# Remove description column if it already exists\n",
    "if 'description' in combined_secondary_df.columns:\n",
    "    combined_secondary_df = combined_secondary_df.drop(columns=['description'])\n",
    "if 'description' in combined_primary_df.columns:\n",
    "    combined_primary_df = combined_primary_df.drop(columns=['description'])\n",
    "\n",
    "# Convert prodcode to string in both dataframes before merging\n",
    "prodcode_dict_df['prodcode'] = prodcode_dict_df['prodcode'].astype(str)\n",
    "combined_secondary_df['prodcode'] = combined_secondary_df['prodcode'].astype(str)\n",
    "\n",
    "# Merge descriptions into combined_secondary_df\n",
    "combined_secondary_df = combined_secondary_df.merge(prodcode_dict_df, on='prodcode', how='left')\n",
    "\n",
    "# Merge descriptions into combined_primary_df\n",
    "combined_primary_df = combined_primary_df.merge(prodcode_dict_df, on='prodcode', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
